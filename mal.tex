\documentclass[12pt, a4paper, oneside]{article}
\usepackage[utf8x]{inputenc}
\usepackage[margin=2.5cm]{geometry}

\usepackage{ucs}

\usepackage{amsmath}

\usepackage{amsfonts}

\usepackage{amssymb}

\usepackage{url}

\usepackage[numbers]{natbib}

\usepackage{setspace}

\usepackage[british]{babel}

\usepackage[nodayofweek]{datetime}

\onehalfspacing

%Set header and footer

\usepackage{fancyhdr}

\pagestyle{fancy}

\fancyhead{}

\fancyfoot{}

%\fancyhead[LE,LO]{\leftmark}

\fancyhead[RE,RO]{\center{Einar Kristoffersen - einar.kristoffersen@uit.no}}

\fancyfoot[C]{\thepage}

\begin{document}
\title{\bfseries {Concurrency in a distributed \\Gigapixel Image Viewer}}
\author{Einar Kristoffersen \\
einar.kristoffersen@uit.no\\
University of Troms\o\\
Troms\o, Norway}
\date{}

\maketitle

%\input{./title.tex}
\newpage
\tableofcontents
\newpage




\section{Abstract}
During the last 10 years the HPDS group of the computer science department at the University of Tromsø has developed the Tromsø Display Wall - a wall size tiled display that contains several displays and computers.

The gigapixel image viewer:


Limitations:
As the current implementation of the Gigapixel image viewer at the Troms\o Displaywall is inefficient, hard to maintain and unstable, the need for a new design is growing. This technical report will describe the new concurrent and flexible design of the Gigapixel image viewer.

lessons learned.

\section{Acknowledgements}
dedicated to..
thank advisor..
thank family
thank friends
\newline
John Marcus Bjørndalen - advisor, 
technical staff working at the displaywall

\section{List of figures}
\section{List of tables}


\section{Introduction}
\subsection{Overview}
About the (Tromsø) Display Wall...

What is the image viewer?

Museum...


\subsection{Description of problem}
What is the problem I am solving?
bottleneck
unstable
more efficient - concurrent
maintainable
configuration - display-cloud

\subsection{Motivation}
What is the motivation for this project?
Maintaining the system
more effective - concurrency
As the current implementation of the Gigapixel image viewer at the Tromsø Displaywall is inefficient, hard to maintain and unstable. Because of this, the need for a new design is growing.  

\subsection{Contributions}
A new concurrent design of the Gigapixel Image Viewer.

\subsection{Limitations/requirements}
What is the requirements?

\subsection{Outline}
What will this report contain?
In section blabla

\section{Related Work}
\subsection{Introduction}
\subsection{others work on the wall}
Get some papers please...

\section{Technical Background - Theoretical framework}
Talk about the technicalities... Golang, concurrency vs parallelism,
\subsection{The Go programming language}
Go is an open source project developed by a team at Google as well as other contributors from the open source community. It was designed to address the problems faced in software development at Google and became a great tool for engineering large software projects.

\subsubsection{Why use Go?}
As mentioned, one of the goals of this Project is to create a implementation that is maintainable. The current implementation of the image viewer is written by using a combination of several languages and as a result, it is hard to maintain the code. 
There was a discussion of which programming language would be best suited for the task. Both Python and Go was solid candidates in order to create a maintainable implementation, but the decision landed on the use of Go to perform this task.
Unlike Python, (C and C++), the Go programming language is build for concurrency. 
Go has the advantage of goroutines..

\subsubsection{Concurrency build on CSP}
Both concurrency and multi-threaded programming have a reputation for being difficult to use. Partly because of complex designs such as pthreads and partly too much focus on low-level details such as mutexes, condition variables and memory barriers. Higher level interfaces enables much simpler code and have been more successful in the past. One of the most successful models for providing high-level support for concurrency comes from CSP, by Tony Hoare. 
Channels... 
This is why the concurrency is build on the idea of CSP...

\subsubsection{Goroutines instead of threads}
Goroutines is a structure of behaviour that makes consistency easy to use in Go. The idea is to multiplex independently executing functions, coroutines, onto a set of threads. When a coroutine blocks, the run-time moves the other coroutines on the same os thread onto a different, runnable thread so they can keep running and not be blocked. The programmer sees none of this, which is exactly the point and makes it very easy to use the interface provided by this language. 
The result, also called a goroutine, can be very cheap. There is little overhead other than the memory for the stack, which is just a few kilobytes.
In order to make the stacks as small as possible, Go uses resizable bounded stacks. Goroutines are given a few kilobytes, which in most cases is enough, but when it isn’t  the runtime grows and shrinks the memory for storing stack automatically. This allows many goroutines to run in a small amount of memory. 
Because of this, you can easy create houndreds of thousands of goroutines in the same address space. If a goroutine was just a thread, the system resources would run out at a much smaller number.
\newline
https://golang.org/doc/faq\#goroutines

\subsection{Concurrency}
\subsubsection{Concurrency vs. Parallelism}
When people hear the word concurrency they often have a tendency to think about the concept of parallelism, a related but quite different term. In programming, concurrency is the organization of independently executing processes, while parallelism is the simultaneous execution of (possibly related) computations. 
When you run a program implemented by the use of concurrency, the executing processes is overlapping each other. This means that operations by different processes can work simultaneously, but they doesn't necessarily start at the same time. 
Parallelism often refers to the technique of making programs fun faster by performing several computations in parallel, literally at the same time. This requires multiple computing units, while the concurrency often refers to techniques that makes a program more usable and requires at least one processing unit. 
Concurrency can be parallelism, but not the other way around.
Concurrency more powerful than parallelism.
\newline
https://blog.golang.org/concurrency-is-not-parallelism


\section{Design}
\subsection{Overview}
The image viewer is designed with a master-slave solution. The master can either be the frontend node or an ordinary laptop and the slaves is the 28 tiles in the cluster. Images located on either the shared disk space or at a web server is fetched by the slaves into shared memory and blitted on a surface viewed by a projector on the master's command. The master listens for input from the user that changes the position variables of the total image put together by each tile viewing several smaller images. The tiles used to view images is determined by configuration files.

About the system -  a brief overview. The method used - master slave. The components involved

\subsection{Configuration}
The viewer is configured using two configuration files. One for the master and one for the slaves. The master uses the configuration file to get the ip-addresses to all the slaves participating in the viewer. The viewer doesn't need to use all 28 tiles. It can use any number of tiles from 1 to 28, but the tiles should be physical neighbours in the total image on the wall. 

The slaves all use the same configuration file. This file contains the id of each participating tile and their corresponding physical position in the configuration. This position is given to each tile regardless of its original position in the big picture, but by comparing it's position to the others in the configuration. 

As long as they all are neighbours...

The configuration files can be located and fetched from the shared disk or from a given url. The master's configuration file is opened and read only once, before starting to send data to the slaves. The slaves' configuration file is opened and read once by each slave. This is done before they start to fetch images and it is necessary to manage the configuration as an initialization when the viewer is started.

\subsection{The master}
The master's main tasks is to:
\begin{enumerate}
\item receive input from the user
\item determine whether this changes the position variables of the composed image
\item pack position variables into a state
\item multicast new states periodically to the slaves in the configuration
\end{enumerate}

In the current design, the master launches one goroutine - a SDL window where the user enters keyboard input and another goroutine multicasting new states to the slaves. These goroutines use a unbuffered channel and one way communication to transfer packed states from the goroutine receiving user input to the goroutine multicasting the states. 
When a new state is fetched from the channel a multicast operation will occur periodically. N times per second will the state be sent by a multicast-like operation. 

receive input -> as result, change variables -> insert to buffer -> (fetch from buffer and start multicast) periodically

Where is the concurrency??

paragraph about data flow

\subsection{Data transfer}
marshal, unmarshal, send, receive
\subsubsection{Program flow}
how it works  - shortly
\subsubsection{Data flow}
about the rates\newline
Whatever kind of input method is chosen, the received input will change the position variables kept at the master. Only when at least one of these variables are changed, they all will be marshalled/packed into a state. Every time a new state is paced it will be inserted into a buffer/queue (FIFO)  where it will be sent out as a multicast to the slaves periodically.
\newline
\newline
Channel as buffer:
Receivers always block until there is data to receive. If the channel is unbuffered, the sender blocks until the receiver has received the value. If the channel has a buffer, the sender blocks only until the value has been copied to the buffer; if the buffer is full, this means waiting until some receiver has retrieved a value.

when a channel is full, the sender waits for another goroutine to make some room by receiving
you can see an unbuffered channel as an always full one : there must be another groutine to take what the sender sends.
\newline
\newline
Variables:
length of buffer/queue
sendrate – how often should we let it send, FPS...
empty the whole queue or just a bit?
\newline
\newline
We do this because we want the movement of the image to be as accurate as possible according to time with a minimal latency. 
We can afford to loose some states in this solution, compared to a solution where you send all states, obtain a huge latency over time and cannot afford loosing any states.

\paragraph{Input rate}
The input rate is the amount of received user input during one second. This is at its peak when the image is constantly moving.
\paragraph{Variable change rate}
The amount of times the position variables (x, y and z) is changed by the user input during one second will from now on be referred to as the “vcr” (variable change rate).
Depending on the vcr is high or low, it might create a bottleneck in form of a queue before a state is multicasted to the slaves. 
\paragraph{Send Rate-muticast}
The send rate is the amount of multicasts the master can complete per second. As the master will send the current state of the position variables periodically, it will have a certain send rate. If the send rate is lower than the vcr, the send queue will be filled up and a latency will occur. As the queue grows larger, the time from receiving user input at the master to the corresponding state is sent from the master also increases. 
Not dealing with this problem will result in a growing latency and (show graph) from tests... 
To deal with this problem we introduce a empty policy saying that if the a state is tried to be inserted into a full buffer or the buffer grows too large, we empty the whole buffer.
\paragraph{blit rate}
Flow charts

\subsubsection{Network flow}
A big design choice is to choose which method to use when sending data to the slaves. Several methods was considered when making this choice. 

\paragraph{Sequential solution}
The sequential solution is based on the master sending only one request to a chosen slave. Depending on how this solution is implemented, the slave forwards this request to some or all of its neighbours in vertical, horizontal or both directions. By introducing a rule about not blitting or forwarding a state that equals the last received state, a slave receiving two or more of the same request will not contribute to spamming the other slaves with the same request over and over again. To make this solution most effective the master should choose the tile that is closest to the center due to the configuration.

The forwarding of requests results in a queue of slaves where the first slave is the one receiving from master and the last one is the one furthest from the center. The slaves between the head and tail of the queue is a collection of the slaves forming the shortest route between these two. 
This approach is said to be sequential because the last slave in the queue must wait until all the salves before it has received and forwarded the request, one by one, to the next slave in the queue.

Unfortunately this approach comes with a few problems. Even if the different queues send their requests concurrently after the head has received it from the master, each slave must wait for the request until the slave above has forwarded it. With a display configuration of 7 tiles in width and 4 tiles in height (maximum amount of tiles), the amount of sends will be 4 after the head received the request from the master. This causes a big latency from master sends the request to the last slave receives is. 

Another problem is because of the latency this approach causes, the spamming rule we introduced will only work to a certain degree. If a slave S receives requests from more than one neighbour, let's say A and B, then this can be the case:
S receives the request r1A, followed by r2A and then r1B.

What happens is that the delay causes S to receive two different requests from A before the first request is received by B. Since the last request received before r1B was r2A, S will both blit and forward this request twice. 

Because of the concurrency, this is not a "clean" sequential solution. That would be to let the master send one request to one slave and let each slave forward only one request further. This in not even considered as an alternative since the last slave in the queue has to wait for all other slaves in the configuration to forward the request. Forwarding the request as much as 27 times would create a even greater delay before the last slave receives the request.

\paragraph{Multicast solution}
The multicast solution is quite simpler. The master sends the same request to all slaves by looping over the ip addresses and starting goroutines that send the request to each of them. This is technically not a multicast since the sending of requests is done concurrently, but it is a multicast like solution.

This will still result in a little delay from when each of the slaves receives the request, but this delay is so little that other factors will have greater impact on the total delay from a request is sent to a request is blitted on the screen. E.g. network traffic at each of the slaves or latency from fetching an image.
\newline
\newline
By comparing the methods mentioned, considering how the latency is scaling when adding more tiles to the configuration the choice of method to use for data transfer over the network was the multicast solution. 

\subsubsection{Memory-cache}
current solution - load all images into ram. what about cache?

\section{Implementation}
\section{Tests/Evaluation}
\section{Results}
\section{Discussion}
\subsection{Draw/Blit}
calculate start position, bounds – only draw images with a position inside the tile's bounds
\subsection{Why SDL?}
In this project SDL was chosen as the graphical framework as it is easy to use and don't need much time setting up. Alternatives could be OpenGL where the graphical effects would have been better. 

\subsection{Limitations of the design}
sdl vs openGl - gliding/smooth movement and smooth zoom
input method - sdl - could be web socket based
cache??

\subsection{Single point of failure}
This system has many "single points of failure". This is partly because of the master - a single node receiving the user input, converting it into a state and forwarding it to all the tiles in the configuration by multicast - but also because of the tiles. If only one of the tiles i the configuration or a tile's projector goes down, there total image viewed will not be complete.  

\section{Further works}
in the future...

\section{Conclusion}
As we can see from the results and evaluation of the implemented design ...
lessons learned...

\newpage

\bibliographystyle{plainnat}

\bibliography{./lt}

\end{document}

